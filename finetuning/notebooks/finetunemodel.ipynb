{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13c422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devinhelgeson/code/normalization_service/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path().resolve().parent.parent  # normalization_service\n",
    "PROC_DIR = BASE_DIR / \"finetuning\" / \"data\" / \"processed\"\n",
    "train_path = PROC_DIR / \"train.jsonl\"\n",
    "test_path = PROC_DIR / \"test.jsonl\"\n",
    "MODEL_SAVE_PATH = BASE_DIR / \"finetuning\" / \"models\" / \"job_title_finetuned\"\n",
    "MODEL_SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Device (force CPU since Mac Intel)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b3fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: 9000\n",
      "Test examples: 1000\n",
      "['Postal Mail Carrier', 'Postal Service Mail Carriers'] 1.0\n",
      "['Knit Goods Mender', 'Coroners'] 0.0\n",
      "['Appliance Assembler', 'Plasterers and Stucco Masons'] 0.0\n",
      "['Leather Craftsman', 'Shoe and Leather Workers and Repairers'] 1.0\n",
      "['Turnstile Collector', 'Civil Engineers'] 0.0\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(path):\n",
    "    examples = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            examples.append(\n",
    "                InputExample(texts=item[\"texts\"], label=float(item[\"label\"]))\n",
    "            )\n",
    "    return examples\n",
    "\n",
    "\n",
    "train_examples = load_dataset(train_path)\n",
    "test_examples = load_dataset(test_path)\n",
    "\n",
    "print(f\"Train examples: {len(train_examples)}\")\n",
    "print(f\"Test examples: {len(test_examples)}\")\n",
    "\n",
    "# Show a sample\n",
    "for ex in train_examples[:5]:\n",
    "    print(ex.texts, ex.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b9d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "print(f\"Loaded model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df96c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader batches: 1125\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 2\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# Evaluator on test set\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    test_examples, name=\"job-title-eval\"\n",
    ")\n",
    "\n",
    "print(f\"Dataloader batches: {len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                                                             \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2250 21:33, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Job-title-eval Pearson Cosine</th>\n",
       "      <th>Job-title-eval Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.816626</td>\n",
       "      <td>0.795058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.810985</td>\n",
       "      <td>0.791026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.821454</td>\n",
       "      <td>0.798121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.821765</td>\n",
       "      <td>0.798163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /Users/devinhelgeson/code/normalization_service/finetuning/models/job_title_finetuned\n"
     ]
    }
   ],
   "source": [
    "WARMUP_STEPS = int(len(train_dataloader) * EPOCHS * 0.1)\n",
    "\n",
    "print(\"Starting fine-tuning...\")\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=EPOCHS,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    output_path=str(MODEL_SAVE_PATH),\n",
    "    evaluation_steps=1000,\n",
    "    use_amp=False,  # No mixed precision on CPU\n",
    ")\n",
    "\n",
    "print(f\"Model saved at: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53d170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'java programmer' and 'computer programmers': 0.8983\n"
     ]
    }
   ],
   "source": [
    "# Quick Test on Sample Pairs\n",
    "fine_tuned_model = SentenceTransformer(str(MODEL_SAVE_PATH), device=device)\n",
    "\n",
    "# Example: compute similarity\n",
    "query = \"java programmer\"\n",
    "candidate = \"computer programmers\"\n",
    "emb1 = fine_tuned_model.encode(query)\n",
    "emb2 = fine_tuned_model.encode(candidate)\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "similarity = dot(emb1, emb2) / (norm(emb1) * norm(emb2))\n",
    "print(f\"Similarity between '{query}' and '{candidate}': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a057f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normalization-service-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
